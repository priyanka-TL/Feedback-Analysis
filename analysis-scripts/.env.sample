# =============================================================================
# FEEDBACK ANALYSIS SYSTEM - ENVIRONMENT CONFIGURATION SAMPLE
# =============================================================================
#
# INSTRUCTIONS:
# 1. Copy this file to .env: cp .env.sample .env
# 2. Fill in your actual API credentials and settings
# 3. DO NOT commit .env to version control (it's in .gitignore)
# 4. Restart scripts after making changes to .env
#
# IMPORTANT: Never share your API keys or AWS credentials!
# =============================================================================

# =============================================================================
# API PROVIDER CONFIGURATION
# =============================================================================
# Supported providers: 
#   - gemini (Google's Generative AI)
#   - bedrock (AWS Bedrock - Claude models)
#
# To switch providers: Change API_PROVIDER value and restart script
# NO CODE CHANGES REQUIRED!
#
# Default: gemini (comment out to use bedrock)
API_PROVIDER=gemini
# API_PROVIDER=bedrock

# =============================================================================
# GEMINI CONFIGURATION (Google AI)
# =============================================================================
# Required if: API_PROVIDER=gemini
#
# Get API key: https://aistudio.google.com/app/apikey
# 
# API_KEYS: Comma-separated list (supports key rotation)
API_KEYS=your_gemini_api_key_here

# MODEL_NAME: Choose from available models
# Default: gemini-2.0-flash-exp
# Options:
#   - gemini-2.0-flash-exp       (Experimental, free tier, high quota)
#   - gemini-2.0-flash           (Stable 2.0 Flash, balanced)
#   - gemini-2.5-flash           (Latest 2.5 Flash, recommended)
#   - gemini-1.5-pro             (Most powerful, higher cost)
MODEL_NAME=gemini-2.0-flash-exp

# =============================================================================
# AWS BEDROCK CONFIGURATION (Claude AI)
# =============================================================================
# Required if: API_PROVIDER=bedrock
#
# Setup:
# 1. Create AWS account if needed
# 2. Go to AWS Console > Bedrock > Model Access
# 3. Request access to Claude models
# 4. Create IAM user with Bedrock permissions
# 5. Get Access Key ID and Secret Access Key
#
# AWS Region: Choose closest region with Bedrock support
# Common regions: us-east-1, us-west-2, eu-west-1, ap-south-1
AWS_REGION=ap-south-1

# AWS Access Credentials
# Keep these SECURE - never commit to version control
AWS_ACCESS_KEY_ID=your_aws_access_key_id
AWS_SECRET_ACCESS_KEY=your_aws_secret_access_key

# BEDROCK_MODEL: Claude model to use
# Default: global.anthropic.claude-sonnet-4-5-20250929-v1:0 (Latest)
# Options:
#   - global.anthropic.claude-sonnet-4-5-20250929-v1:0  (Latest, RECOMMENDED)
#   - anthropic.claude-3-5-sonnet-20241022-v2:0         (Claude 3.5 Sonnet v2)
#   - anthropic.claude-3-5-sonnet-20240620-v1:0         (Claude 3.5 Sonnet v1)
#   - anthropic.claude-3-opus-20240229-v1:0             (Most powerful, highest cost)
#   - anthropic.claude-3-sonnet-20240229-v1:0           (Balanced cost/quality)
#   - anthropic.claude-3-haiku-20240307-v1:0            (Fast and cheap)
BEDROCK_MODEL=global.anthropic.claude-sonnet-4-5-20250929-v1:0

# BEDROCK_MODEL_VERSION: Anthropic API version
# Default: bedrock-2023-05-31 (current stable)
BEDROCK_MODEL_VERSION=bedrock-2023-05-31

# =============================================================================
# COMMON API CONFIGURATION
# =============================================================================
# These settings apply to BOTH Gemini and Bedrock providers

# TEMPERATURE: Controls response randomness/creativity
# Range: 0.0 to 2.0 (or 0.0 to 1.0 for some models)
# - 0.0: Deterministic (best for structured data)
# - 0.3: Low randomness (good for analysis)
# - 0.7: Balanced creativity
# - 1.0+: High creativity (more variations)
# Default: 0.3 (recommended for feedback analysis)
TEMPERATURE=0.3

# MAX_TOKENS: Maximum response length
# Range: 1 to model's max (usually 2048-4096)
# Default: 4096
MAX_TOKENS=4096

# MAX_RETRIES: Number of retry attempts on failure
# Default: 5
MAX_RETRIES=5

# INITIAL_RETRY_DELAY: Initial delay before first retry (milliseconds)
# Default: 2000 (2 seconds)
# Subsequent retries use exponential backoff (delay * 2^attempt)
INITIAL_RETRY_DELAY=2000

# REQUEST_DELAY: Delay between API requests (milliseconds)
# Default: 1000 (1 second)
# Prevent rate limiting by spacing out requests
REQUEST_DELAY=1000

# RATE_LIMIT_DELAY: Delay when rate limit hit (milliseconds)
# Default: 60000 (1 minute)
# Increased to allow quota recovery
RATE_LIMIT_DELAY=60000

# TOKENS_PER_MINUTE: API rate limit tokens per minute
# Default: 2500000 (2.5M tokens/minute)
# Varies by provider and quota tier
TOKENS_PER_MINUTE=2500000

# TOKEN_BUFFER: Use this percentage of the rate limit
# Default: 0.85 (use 85% of limit to stay safe)
# Range: 0.5 to 1.0
TOKEN_BUFFER=0.85

# =============================================================================
# FILE PATHS AND INPUTS
# =============================================================================
# Paths can be absolute or relative to script location

# INPUT_CSV: Path to input CSV file
# Default: ./input.csv
INPUT_CSV=./input.csv

# OUTPUT_CSV: Path to output CSV file
# Default: ./output.csv
OUTPUT_CSV=./output.csv

# PROGRESS_FILE: Path to progress tracking file
# Default: ./progress.json
PROGRESS_FILE=./progress.json

# LOG_DIR: Directory for log files
# Default: ./logs
LOG_DIR=./logs

# DEBUG_DIR: Directory for debug output
# Default: ./debug
DEBUG_DIR=./debug

# REPORTS_DIR: Directory for generated reports
# Default: ./reports
REPORTS_DIR=./reports

# QUESTIONS_CONFIG: Path to questions configuration file
# Default: ./questions-config.json
# This file defines the survey questions and categorization schema
QUESTIONS_CONFIG=./questions-config.json

# QUESTION_COLUMNS: Path to question columns mapping file
# Default: ./question-columns.json
QUESTION_COLUMNS=./question-columns.json

# =============================================================================
# PROCESSING CONFIGURATION
# =============================================================================

# START_ROW: Which row to start processing from
# Default: 0 (first row)
# Useful for resuming interrupted processing
START_ROW=0

# MAX_ROWS: Maximum rows to process (null = all rows)
# Default: null (process all)
# Useful for testing with subset of data
# MAX_ROWS=100

# BATCH_SIZE: Number of rows to process per batch
# Default: 10
BATCH_SIZE=10

# SAVE_PROGRESS_EVERY: Save progress every N batches
# Default: 10
SAVE_PROGRESS_EVERY=10

# LOG_EVERY: Log progress every N rows
# Default: 5
LOG_EVERY=5

# DELAY_BETWEEN_ROWS: Delay between processing rows (milliseconds)
# Default: 0 (no delay)
# Useful if you need to throttle processing
DELAY_BETWEEN_ROWS=0

# MAX_RESPONSES_PER_BATCH: Maximum responses to process in one batch
# Default: 1000
MAX_RESPONSES_PER_BATCH=1000

# SKIP_FAILED_BATCHES: Skip batch if processing fails (true/false)
# Default: false (stop on failure)
SKIP_FAILED_BATCHES=false

# =============================================================================
# COLUMN NAMES
# =============================================================================
# Map CSV column names to internal field names

# ID_COLUMN: Column name for unique row identifier
# Default: id
ID_COLUMN=id

# DISTRICT_COLUMN: Column name for district/location
# Default: District
DISTRICT_COLUMN=District

# TIMESTAMP_COLUMN: Column name for timestamp
# Default: Timestamp
TIMESTAMP_COLUMN=Timestamp

# =============================================================================
# VALIDATION CONFIGURATION
# =============================================================================

# MIN_RESPONSE_LENGTH: Minimum characters to consider a response valid
# Default: 3
MIN_RESPONSE_LENGTH=3

# =============================================================================
# CATEGORIZATION CONFIGURATION
# =============================================================================

# INCLUDE_REASONING: Include reasoning in categorization output (true/false)
# Default: true
INCLUDE_REASONING=true

# ALLOW_NEW_CATEGORIES: Allow AI to suggest new categories (true/false)
# Default: false (stick to predefined categories)
ALLOW_NEW_CATEGORIES=false

# =============================================================================
# GRAMMAR IMPROVEMENT CONFIGURATION
# =============================================================================

# PRESERVE_FORMATTING: Keep original formatting when improving grammar (true/false)
# Default: true
PRESERVE_FORMATTING=true

# CREATE_BACKUP: Create backup before processing (true/false)
# Default: true
CREATE_BACKUP=true

# =============================================================================
# INSIGHTS EXTRACTION CONFIGURATION
# =============================================================================

# EXAMPLES_PER_ITEM: Number of supporting examples per insight
# Default: 3
# Range: 1-10
EXAMPLES_PER_ITEM=3

# =============================================================================
# LOGGING CONFIGURATION
# =============================================================================

# LOG_LEVEL: Logging verbosity
# Options: error, warn, info, debug, trace
# Default: info
LOG_LEVEL=info